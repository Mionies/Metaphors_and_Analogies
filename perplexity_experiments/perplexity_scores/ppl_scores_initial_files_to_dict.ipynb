{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e79d79-e790-4c82-886a-73be82f90cad",
   "metadata": {},
   "source": [
    "## Load all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "from datasets import load_dataset\n",
    "\n",
    "pair_sets = [ \"Cardillo\", \"Jankowiak\"]\n",
    "quad_sets = [ \"SAT*\", ]#'Green']\n",
    "\n",
    "all_data ={\n",
    "    \"Cardillo\": load_dataset('json', data_files='../../datasets/Cardillo/cardillo.jsonl'),\n",
    "    \"Jankowiak\":load_dataset('json', data_files='../../datasets/Jankowiak/Jankowiak.jsonl'),\n",
    "    \"SAT*\":load_dataset('json', data_files='../../datasets/SAT_STAR/sat_star.jsonl'),\n",
    "    \"SAT\":load_dataset('json', data_files='../../datasets/sat/sat.jsonl')\n",
    "    #Green\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ea984",
   "metadata": {},
   "source": [
    "## Create all datasets utils dictionaries\n",
    "- datasets_sent2label\n",
    "- datasets_sent2idx\n",
    "- datasets_idx2sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b441de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sent2label = {}\n",
    "datasets_sent2idx = {}\n",
    "datasets_idx2sent = {}\n",
    "\n",
    "\n",
    "for dataset in pairs_sets:\n",
    "    datasets_sent2label[dataset] = {}\n",
    "    datasets_sent2idx[dataset] = {}\n",
    "    datasets_idx2sent[dataset] = {}\n",
    "    n = 0\n",
    "    for i,e in enumerate(all_data[dataset][\"test\"]):\n",
    "        for j,f in enumerate(e[\"sentences\"]):\n",
    "            datasets_sent2label[dataset][f] = e[\"labels\"][j]\n",
    "            datasets_sent2idx[dataset][f] = n\n",
    "            datasets_idx2sent[dataset][n] = f\n",
    "            n+=1\n",
    "            \n",
    "            \n",
    "for dataset in quad_sets:\n",
    "    datasets_sent2label[dataset] = {}\n",
    "    datasets_sent2idx[dataset] = {}\n",
    "    datasets_idx2sent[dataset] = {}\n",
    "    n = 0\n",
    "    for i,e in enumerate(all_data[dataset][\"test\"]):\n",
    "        for j,f in enumerate(e[\"pairs\"]):\n",
    "            t = eval(e[\"stem\"])\n",
    "            t.extend(f)\n",
    "            t = tuple(t)\n",
    "            datasets_sent2label[dataset][t] = e[\"labels\"][j]\n",
    "            datasets_sent2idx[dataset][t] = n\n",
    "            datasets_idx2sent[dataset][n] = t\n",
    "            n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e332793",
   "metadata": {},
   "source": [
    "## All models perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_scores = \"asahi_results/metaphor_results/scores_no_prompt/\"\n",
    "ppl_openai_scores = \"asahi_results/metaphor_results/scores_openai_no_prompt/\"   \n",
    "\n",
    "no_prompt = os.listdir(ppl_scores)\n",
    "no_prompt_openai = os.listdir(ppl_openai_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcebc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_prompt = {}\n",
    "\n",
    "for x in no_prompt+no_prompt_openai:\n",
    "    p = json.load(open(asahi_no_prompt+\"/\"+x))\n",
    "    x = x.replace(\".Metaphors_and_Analogies_\",\"|\")\n",
    "    w = x.split(\"|\")\n",
    "    model,dataset=w[0],w[1][:-10]\n",
    "    if not dataset in results_no_prompt:\n",
    "        results_no_prompt[dataset]={}\n",
    "    if not model in results_no_prompt[dataset]:    \n",
    "        results_no_prompt[dataset][model] = {\"text\":[],\"true\":sum(p[\"labels\"],[]),\"idx\":[],\"score\":[]}\n",
    "    for i,y in enumerate(p[\"perplexity\"]):\n",
    "        results_no_prompt[dataset][model][\"score\"].append(y[\"score\"])\n",
    "        results_no_prompt[dataset][model][\"idx\"].append(y[\"index\"])\n",
    "        results_no_prompt[dataset][model][\"text\"].append(datasets_idx2sent[dataset][i])\n",
    "        assert results_no_prompt[dataset][model][\"true\"][i]==datasets_sent2label[dataset][datasets_idx2sent[dataset][i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d566fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"utils_dictionaries/\"\n",
    "with open(output+\"results_no_prompt_zero_shot.json\", \"w\") as outfile:\n",
    "    json.dump(results_no_prompt,outfile,indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f31fbb",
   "metadata": {},
   "source": [
    "## SAT_MET Dictionaries \n",
    "- satsetid : sat quadruples to set_ids\n",
    "- satlabs : quadruples to labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efefc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "satlabs = {}\n",
    "satsetid = {}\n",
    "for x in all_data[\"SAT*\"]:\n",
    "    for i,pair in enumerate(x[\"pairs\"]):\n",
    "        target = eval(x[\"stem\"])\n",
    "        target.extend(pair)\n",
    "        satlabs[tuple(target)]=x[\"labels\"][i]\n",
    "        satsetid[tuple(target)]=x[\"id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abcd56",
   "metadata": {},
   "source": [
    "### SAT_met no prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"asahi_results/sat-scores-no-prompt-other-models/\"\n",
    "a = os.listdir(res_dir)\n",
    "a = [x for x in a if \"sat_full_None.prompt\" in x]\n",
    "didisat = {}\n",
    "\n",
    "sat_no_score = {}\n",
    "for x in a:\n",
    "    p = json.load(open(res_dir+x))\n",
    "    model = (x[:-26])\n",
    "    sat_no_score[model]={\"text\":[],\"score\":[],\"true\":[],\"idx\":[]}\n",
    "    for i,y in enumerate(p):\n",
    "        q = {}\n",
    "        text = y[\"input\"]+y[\"output\"]\n",
    "        flag = 0\n",
    "        for quad in satlabs:\n",
    "            c = 0\n",
    "            for word in quad:\n",
    "                if word in text :\n",
    "                    c+=1\n",
    "            if c==4:\n",
    "                mes4mots = quad\n",
    "                flag = 1\n",
    "        if flag==1:\n",
    "            sat_no_score[model][\"score\"].append(y[\"score\"])\n",
    "            sat_no_score[model][\"text\"].append(mes4mots)\n",
    "            sat_no_score[model][\"true\"].append(satlabs[mes4mots])\n",
    "            sat_no_score[model][\"idx\"].append(satsetid [mes4mots])\n",
    "            didisat[i]=mes4mots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = json.load(open(\"asahi_results/gpt3-scores-noprompt-SAT/davinci_sat_full_None.prompt.json\"))\n",
    "sat_no_score[\"davinci\"] = {\"text\":sat_no_score[model][\"text\"],\"score\":[],\"true\":sat_no_score[model][\"true\"],\"idx\":sat_no_score[model][\"idx\"]}\n",
    "n = 0\n",
    "for x in p:\n",
    "    for y in x[1]:\n",
    "        if n in didisat:\n",
    "            sat_no_score[\"davinci\"][\"score\"].append(y)\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c64656",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"utils_dictionaries/\"\n",
    "with open(output+\"results_sat_no_prompt_zero_shot.json\", \"w\") as outfile:\n",
    "    json.dump(sat_no_score,outfile,indent=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
